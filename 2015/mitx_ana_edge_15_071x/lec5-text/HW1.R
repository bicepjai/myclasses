wiki = read.csv("wiki.csv")
table(wiki$Vandal)
library(tm)
corpus = Corpus(VectorSource(wiki$Added))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtmAdded = DocumentTermMatrix(corpus)
dtmAdded
sparseAdded = removeSparseTerms(dtmAdded, 0.997)
sparseAdded
wordsAdded = as.data.frame(as.matrix(sparseAdded))
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
corpus = Corpus(VectorSource(wiki$Removed))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtmRemoved = DocumentTermMatrix(corpus)
dtmRemoved
sparseRemoved = removeSparseTerms(dtmRemoved, 0.997)
sparseRemoved
wordsRemoved = as.data.frame(as.matrix(sparseRemoved))
str(wordsRemoved)
wikiWords = cbind(wordsAdded, wordsRemoved)
wikiWords$Vandal = wiki$Vandal
str(wikiWords)
library(caTools)
set.seed(123)
spl = sample.split(wikiWords$Vandal, 0.7)
train = subset(wikiWords, spl == TRUE)
test = subset(wikiWords, spl == FALSE)
table(train$Vandal)
1270/nrow(train)
1443/nrow(train)
library(rpart)
library(rpart.plot)
wikiCART = rpart(Vandal~., data=train, method="class")
prp(wikiCART)
pred = predict(wikiCART, newdata=test)
pred.prob = pred[,2]
table(test$Vandal, pred.prob >= 0.5)
630(nrow(test))
630/(nrow(test))
grepl("cat","dogs and cats",fixed=TRUE)
grepl("cat","dogs and rats",fixed=TRUE)
wikiWords2 = wikiWords
wikiWords2$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
table(wikiWords2)
table(wikiWords2$HTTP)
wikiTrain2 = subset(wikiWords2, spl==TRUE)
wikiTest2 = subset(wikiWords2, spl==FALSE)
wikiCART2 = rpart(Vandal~., data=wikiTrain2, method="class")
prp(wikiCART2)
pred2 = predict(wikiCART2, newdata=wikiTest2)
pred2.prob = pred2[,2]
table(wikiTest2$Vandal, pred2.prob >= 0.5)
(609+57)/nrow(wikiTest2)
wikiWords2$NumWordsAdded = rowSums(as.matrix(dtmAdded))
wikiWords2$NumWordsRemoved = rowSums(as.matrix(dtmRemoved))
summary(wikiWords2$NumWordsAdded)
wikiTrain2 = subset(wikiWords2, spl==TRUE)
wikiTest2 = subset(wikiWords2, spl==FALSE)
wikiCART2 = rpart(Vandal~., data=wikiTrain2, method="class")
prp(wikiCART2)
pred2 = predict(wikiCART2, newdata=wikiTest2)
pred2.prob = pred2[,2]
table(wikiTest2$Vandal, pred2.prob >= 0.5)
(514+248)/nrow(wikiTest2)
wikiWords3 = wikiWords2
wikiWords3$Minor = wiki$Minor
wikiWords3$Loggedin = wiki$Loggedin
wikiTrain3 = subset(wikiWords3, spl==TRUE)
wikiTest3 = subset(wikiWords3, spl==FALSE)
wikiCART3 = rpart(Vandal~., data=wikiTrain3, method="class")
prp(wikiCART3)
pred3 = predict(wikiCART3, newdata=wikiTest3)
pred3.prob = pred3[,2]
table(wikiTest3$Vandal, pred3.prob >= 0.5)
(595+241)/nrow(wikiTest2)
savehistory("~/Projects/edx/AnalyticsEdge_MITx15_071x/lec5/HW1.R")
