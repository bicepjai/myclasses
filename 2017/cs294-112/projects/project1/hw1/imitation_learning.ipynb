{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"993cb867-47ad-4368-bbbb-10db0850e0ad\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"993cb867-47ad-4368-bbbb-10db0850e0ad\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"993cb867-47ad-4368-bbbb-10db0850e0ad\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '993cb867-47ad-4368-bbbb-10db0850e0ad' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"993cb867-47ad-4368-bbbb-10db0850e0ad\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"993cb867-47ad-4368-bbbb-10db0850e0ad\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "import load_policy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# bokeh stuff\n",
    "from ipywidgets import interact\n",
    "\n",
    "from bokeh.io import push_notebook, output_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "import bokeh.plotting as bk\n",
    "output_notebook()\n",
    "\n",
    "# plotly stuff\n",
    "import plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "py.tools.set_credentials_file(username='bicepjai', api_key='iXgHGAFTTFcbJIuYCnE7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Expert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_policy_file = \"experts/Walker2d-v1.pkl\"\n",
    "envname = 'Walker2d-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-22 23:24:22,455] Making new env: Walker2d-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "('obs', (1, 17), (1, 17))\n",
      "loaded and built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep_limit 1000\n",
      "roll_outs --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [2:18:33<00:00, 16.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('returns', [5574.9011693718085, 5581.2722455961193, 5497.0422288474374, 5601.1923917659542, 5509.993713908636, 5480.2229189221398, 5558.9363914611622, 5567.261694998183, 5553.1163013987234, 5459.5582531093924, 5589.7833157516543, 5598.541835688563, 5527.408396838905, 5604.5112604474598, 5576.1762753508374, 5472.6274898712172, 5448.5958998994902, 5515.2364265244105, 5533.8242553249229, 5553.5305519534331, 5520.207963394434, 5561.2703102132973, 5483.620989680011, 5496.9926382696467, 5511.7512062520818, 5519.1413193048847, 5521.3512741914874, 5510.0000170650992, 5575.0653783183016, 5547.8656230828701, 5589.7039263791276, 5574.7918877301381, 5531.0485523272437, 5534.1631231280408, 5560.835948747349, 5550.3483060650315, 5451.6375331607696, 5561.6972233451788, 5413.9022662939769, 5373.7366830101337, 5560.724669810691, 5555.8876179307663, 5532.8985046730295, 5554.9756396497251, 5567.0885710690363, 5537.1180125275359, 5531.0165872519119, 5465.8350577301007, 5457.9122093694623, 5520.3809475108292, 5507.7696789700003, 5592.2335916099346, 5509.4906390535962, 5590.5159053019461, 5372.8886457728895, 5019.7724443981388, 5579.9754239591584, 5534.2856252878582, 5513.165878942481, 5550.3441608534395, 5430.8049488459765, 5508.3502468434972, 5436.3238466557241, 5601.3361530032371, 5509.1246025197815, 5457.839055550744, 5529.4931415935598, 5583.5598545775429, 5582.0497038839203, 5622.4638231390018, 5531.5430871021008, 5609.4930706023752, 5553.2460965703494, 5553.5847928747362, 5588.1682944915146, 5550.8182808482634, 5556.6337160406129, 5428.7186927541279, 5544.3263247070863, 5568.8146939704811, 5579.9969706653637, 5480.4382015842639, 5565.7176306130823, 5412.5068651355177, 5598.1215594062614, 5433.2992777780182, 5467.559432383744, 5578.738308699898, 5505.5219505093573, 5467.6890809180995, 5508.4850121888057, 5572.2291582444914, 5472.2133122205441, 5375.4479943806982, 5523.8022219485492, 5522.1175760839978, 5493.297394434323, 5466.358247797848, 5578.6020763315064, 5620.5255490124082, 5437.6061973118585, 5561.3074518307703, 5579.1922756756767, 5493.5625478993461, 5420.5707750466654, 5515.9390513828957, 5572.1710777212556, 5564.7976032373526, 5569.3589894204006, 5158.0633412624065, 2626.5109123653815, 5490.7303788050904, 5518.2255086058431, 5567.9702117216966, 5534.9868922461783, 5599.5043885572941, 5460.4385181445459, 5541.5316316169292, 5490.4086970990156, 5504.6674414420368, 5077.4486955581679, 5596.6535223592991, 5563.024342475449, 5517.3544699958802, 5532.9414944536511, 5470.8964464193959, 5490.6392355811349, 5553.617903403072, 5410.5674586860596, 5549.129271234121, 5487.8166387138745, 5494.9897263803405, 5545.5497260163438, 5504.2090764344757, 5534.8547117308344, 5544.4817944628749, 5540.843937568302, 5410.1490709020782, 5412.8586352651, 5537.0962011654083, 5556.2229421626453, 5567.9183733039417, 5233.6490906371628, 5622.0443562432283, 5518.6139248729969, 5534.1551586489086, 5588.952589045286, 5467.9718726760548, 5577.8951687367562, 5376.5070326529149, 5523.8227214309036, 5543.9260843621905, 5524.2854461644029, 5533.0831986909407, 5488.6872042849627, 5564.9502439345615, 5524.0119783539149, 5586.4215009949357, 5590.012033714801, 5568.6019936458706, 5538.5895080927321, 5484.2780317652696, 5530.3549647859154, 5543.5301141505133, 5581.827101845437, 5476.8924941185287, 5565.6846785372863, 5475.3918137695673, 5482.2637859403994, 5566.5408036344079, 5475.4141815422945, 5431.9902009998259, 5471.5358248432094, 5430.8132529436461, 5508.9321137824181, 5573.7495551998527, 5540.858600949653, 5535.3080568517889, 5566.1797171356748, 5566.8773410591712, 5529.6659968644062, 5473.6777625238165, 5537.4722333516847, 5146.7580519027351, 5472.1760200383333, 5541.3362901474711, 5578.6366156584472, 5607.7823068954222, 5561.7389008257041, 5460.0976501750274, 5517.9317871358226, 5592.1031646652427, 5456.1913982123888, 5604.6296382572637, 5602.1519717661822, 5455.5816731871719, 5467.0484987058499, 5576.3150060602229, 5534.9101993735221, 5571.9982704249769, 5579.5959514757087, 5389.2840662899498, 5488.9873965171537, 5413.495059079637, 5422.3906865721756, 5557.8053313802839, 5535.6616866988352, 5539.3908030849179, 5437.9140358510995, 5454.4570633516769, 5551.3547897300341, 5566.8290490764821, 5558.0592868872473, 5540.9874994286065, 5552.4388272911438, 5570.6367866630771, 5552.3072266460822, 5596.0764975507327, 5495.0391103149341, 5572.0847053547213, 5560.7619777780947, 5550.915163710175, 5512.2117925679177, 5450.9362800727158, 5318.2543472393281, 5527.2492907925762, 5424.644518380037, 5335.3184714341123, 5526.2668482639292, 5395.5170649652373, 5558.5649943621265, 5576.4881929057183, 5562.6695700499104, 5518.3651553791015, 5485.2748693715366, 5566.1219965483842, 5523.2908484423178, 5543.601436428803, 5525.1906086441504, 5520.6110660138238, 4064.1698800359245, 5505.055180717316, 5526.5035940038015, 5537.8950198190978, 5600.2865195801678, 5601.5677104933366, 5485.7245248971685, 5542.8766879349541, 5513.8878767939932, 5612.5286712696161, 5546.2012725300956, 5412.5637858641066, 5508.3117568893795, 5571.0432045886209, 5549.7007826413301, 5521.5048733635595, 5479.9202152898351, 5543.0702050115124, 5497.8722236915664, 5534.6610264189258, 5553.3297591519231, 5567.0178371784878, 5470.5372070912854, 5487.4476697600894, 5441.1979326021874, 5583.3525292621998, 5439.8102785192123, 5468.2797990875461, 5519.4300223815289, 5551.2641285016962, 5510.287142520966, 5565.9128093174932, 5453.3074299481868, 5539.5308831285229, 5634.8784582104463, 5477.9656955534128, 5536.9834577244856, 5432.106252725167, 5509.2037605153455, 5575.1912354586302, 5431.6170427595343, 5559.6260306944696, 5563.7194059659614, 5515.4237658041993, 5582.3458224280648, 5559.5344349391089, 5589.0344882949303, 5506.5996510968371, 5478.1409659350429, 5551.3566857263741, 5596.9421603616947, 5503.1201658824757, 5522.9935695430431, 5468.1320287591825, 5585.0052868086495, 5563.4197203841632, 5521.8686346174709, 5543.04400191068, 5492.6181859789021, 5573.4870827720551, 5516.554128452447, 5461.7925735746821, 5507.7828933506808, 5549.3944895895565, 1577.1119148394746, 5406.305395773119, 5527.2676961585648, 5525.7090503610762, 5549.3549578432185, 5527.679021667961, 5585.3745489903322, 5512.0743570142104, 5592.383193084288, 5569.3745270562431, 5584.7663664493539, 5473.7867387630304, 5439.3173195599275, 5562.4071886552201, 5510.5107936716367, 5498.1864975848384, 5396.812321763935, 5534.6257248519823, 5500.2491095674031, 5574.7939871568515, 5486.9503786778441, 5486.8349729038637, 5554.7390303938246, 5530.1076152821834, 5532.77890279035, 5512.7440440867886, 5578.5853292460333, 5448.1160903246382, 5514.3314212699797, 5547.710680810992, 5515.1285496310111, 5573.5661932289195, 5539.2912570909175, 5462.1472774901404, 5414.9516761127634, 5519.0599829345292, 5569.1428421199244, 5342.3322935811802, 5465.4213264418177, 5416.2320883957891, 5527.3769293304358, 5509.6763500932939, 5488.8335189311083, 5573.2692437637979, 5547.6115832019468, 5512.405899309505, 5532.2365946915552, 5544.5108120813475, 5553.2465007041865, 5520.7896459799722, 5544.5087210860565, 5435.5220992560062, 5544.7369762322314, 5594.9338470540315, 5583.6147586579364, 5542.3606295658446, 5581.1505695138412, 5191.9929856670624, 5480.9588708223619, 5509.16544656935, 5565.6666067968999, 5578.7628674298048, 5569.2658488764246, 5487.1432878452333, 5597.6314398286895, 5507.1066864275572, 5552.2805099537227, 5553.4858679343042, 5525.6744384435942, 5492.7270974074336, 5464.1129155613316, 5539.0626323269635, 5416.3305675140473, 5580.9487409453441, 5520.2431997330686, 5538.4383129241351, 5415.6043701406534, 5557.5395994458268, 5513.7421735555499, 5516.1927396245583, 5614.4904462745462, 5507.9557867516769, 5485.9354073559307, 5605.5977220204441, 5520.0438770657847, 5458.9329909756798, 5560.6745365192146, 5482.8448697639342, 5528.2403572209587, 5425.8254671634641, 5463.6219917457765, 5522.192720071218, 5522.9670093013201, 5440.9894163232448, 5585.672799388296, 5406.0665320486651, 5576.0420698793041, 5453.8931411679287, 5594.3394336473712, 5555.0845817881991, 5589.1239411071483, 5501.7462582503131, 5544.0789613766729, 5319.3274362560041, 5524.0239275332597, 5573.8799094333745, 5595.7265598515087, 5496.96231344027, 5566.6155639387498, 5495.7432110066802, 5607.500534332301, 5467.7007391231145, 5585.2723611471847, 5493.1561095714596, 5562.6363378632286, 5564.6758371501801, 5509.8754494191317, 5577.6689150266793, 5554.5806831512009, 5453.9991705006287, 5545.1538486758254, 5538.7239736682595, 5493.3311265503571, 5573.360446483196, 5467.1361569119499, 5542.4992506182343, 5431.7390383175934, 5549.1960588620796, 5556.2453765311257, 5551.9241351473138, 5567.1156933165421, 5525.1979663202374, 5441.0314991661908, 5496.5631625377073, 5530.0880772150813, 5515.5413616713531, 5529.5349258952792, 5525.1046405266607, 5533.153778091536, 5541.2530239885236, 5566.3261882890738, 5524.2758430300746, 5593.8816868704889, 5526.742271553454, 5558.2397892313684, 5575.2493245269734, 5585.9046156094582, 5196.7097336385314, 5532.1714671201271, 5528.8865527172111, 5580.8263647638705, 5574.1338703538149, 5476.1059675768611, 5611.340118988297, 5426.8030063735177, 5517.9548140531015, 5572.2722234731464, 5438.4144519701676, 5554.0675556083415, 5576.4830422984114, 5497.3687960822544, 5572.2262656839757, 5561.3841817322527, 5544.3088102040965, 5583.2173446434126, 5613.0081409738887, 5554.8351322627223, 5470.8999636805938, 5525.1087303470458, 5579.4564353277683, 5544.2640962934347, 5430.2202958847229, 5547.0184779526471, 5381.3489169131844, 5542.9245865068578, 5489.4329627333882, 5588.8077575971292, 5470.25873541694, 5469.0788668441564, 5569.8462896703249, 5456.8754762660292, 5543.8985857610542, 5556.6943746486386, 5562.6259749082847, 5572.6240937565181, 5517.0372321820423, 5552.4587157252199, 5390.2051559896281, 5533.399247862405, 5568.5974815305181, 5567.9784558278989, 5555.0673784224045, 5501.0518982224148, 5484.7304020210813, 5538.2821614754321, 5523.0105420691516])\n",
      "('mean return', 5501.9883343478259)\n",
      "('std of return', 238.22694324423887)\n",
      "['observations', 'actions']\n",
      "observations-----------------(498706, 17)\n",
      "actions----------------------(498706, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "render = True\n",
    "max_timesteps = 1000\n",
    "num_rollouts = 500\n",
    "\n",
    "def generate_expert_data():\n",
    "    print('loading and building expert policy')\n",
    "    policy_fn = load_policy.load_policy(expert_policy_file)\n",
    "    print('loaded and built')\n",
    "\n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "\n",
    "        import gym\n",
    "        env = gym.make(envname)\n",
    "        max_steps = max_timesteps or env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "        print(\"timestep_limit {}\".format(max_steps))\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        print(\"roll_outs --\")\n",
    "        obs = env.reset()\n",
    "        for i in tqdm(range(num_rollouts)):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "\n",
    "        print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "\n",
    "        expert_data = {'observations': np.array(observations),\n",
    "                       'actions': np.array(actions)}\n",
    "\n",
    "        # save and load\n",
    "        np.savez('traindata.npz', observations=np.array(observations), actions=np.array(actions))\n",
    "        data = np.load('traindata.npz') \n",
    "        print data.files \n",
    "        X = data['observations'] \n",
    "        y = data['actions']\n",
    "        print(\"observations-----------------{}\".format(X.shape))\n",
    "        print(\"actions----------------------{}\".format(y.shape))\n",
    "\n",
    "generate_expert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with Tensorflow sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup layers\n",
    "# this placeholder will contain our input digits, as flat vectors\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "\n",
    "# Keras layers can be called on TensorFlow tensors:\n",
    "x = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\n",
    "\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "#train\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "K.get_session().run(tf.global_variables_initializer())\n",
    "with sess.as_default():\n",
    "    for i in range(1000):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1]})\n",
    "\n",
    "#statistics\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Ploting APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history_dict):\n",
    "    acc_values = history_dict['loss']\n",
    "    val_acc_values = history_dict['val_loss']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "    plt.plot(epochs, acc_values, 'bo')\n",
    "    plt.plot(epochs, val_acc_values, 'b+')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "def plotly_history(history_dict):\n",
    "    fig1 = plt.figure()\n",
    "    acc_values = history_dict['loss']\n",
    "    val_acc_values = history_dict['val_loss']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(epochs, acc_values, 'bo')\n",
    "    plt.plot(epochs, val_acc_values, 'b+')\n",
    "    return fig1\n",
    "\n",
    "# fig = plotly_history(history.history)\n",
    "# py.plotly.iplot_mpl(fig, strip_style = True)\n",
    "\n",
    "def bokeh_history(history_dict):\n",
    "    acc_values = history_dict['loss']\n",
    "    val_acc_values = history_dict['val_loss']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "    p = figure(tools=\"pan,box_zoom,reset,save\",\n",
    "            plot_height=400, plot_width=800,\n",
    "            title=\"loss vs epoch\", \n",
    "            x_axis_label='epoch', \n",
    "            y_axis_label='loss')\n",
    "    p.line(epochs, acc_values, legend=\"train_acc\", line_color=\"blue\")\n",
    "    p.line(epochs, val_acc_values, legend=\"val_acc\", line_color=\"orange\")\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = np.load('walker2d-v1-r200-t100_traindata.npz')\n",
    "random_sampling = 2344\n",
    "\n",
    "observations = train_data['observations']\n",
    "actions = train_data['actions'][:, 0]\n",
    "\n",
    "print(\"observations {}\".format(train_data['observations'].shape))\n",
    "print(\"actions {}\".format(train_data['actions'].shape))\n",
    "\n",
    "N, input_dims = train_data['observations'].shape\n",
    "N1, _, output_dims = train_data['actions'].shape\n",
    "\n",
    "assert(N1 == N)\n",
    "\n",
    "# Train-Test-Validation split\n",
    "test_split = 0.20\n",
    "validation_splot = 0.20\n",
    "X, X_test, y, y_test = train_test_split(observations, actions, test_size=test_split, random_state=random_sampling)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_splot, random_state=random_sampling)\n",
    "\n",
    "print(\"X {}\".format(X.shape))\n",
    "print(\"y {}\".format(y.shape))\n",
    "\n",
    "print(\"X_test {}\".format(X_test.shape))\n",
    "print(\"y_test {}\".format(y_test.shape))\n",
    "\n",
    "print(\"X_train {}\".format(X_train.shape))\n",
    "print(\"y_train {}\".format(y_train.shape))\n",
    "\n",
    "print(\"X_val {}\".format(X_val.shape))\n",
    "print(\"y_val {}\".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#means and stds\n",
    "X_mean, y_mean, X_std, y_std = X.mean(axis=0), y.mean(axis=0), X.std(axis=0), y.std(axis=0)\n",
    "X_test_mean, y_test_mean, X_test_std, y_test_std = X_test.mean(axis=0), y_test.mean(axis=0), X_test.std(axis=0), y_test.std(axis=0)\n",
    "X_train_mean, y_train_mean, X_train_std, y_train_std = X_train.mean(axis=0), y_train.mean(axis=0), X_train.std(axis=0), y_train.std(axis=0)\n",
    "X_val_mean, y_val_mean, X_val_std, y_val_std = X_val.mean(axis=0), y_val.mean(axis=0), X_val.std(axis=0), y_val.std(axis=0)\n",
    "\n",
    "# standardizing data\n",
    "# X_test -= X_test_mean\n",
    "# X_test /= X_test_std\n",
    "\n",
    "# X_train -= X_train_mean\n",
    "# X_train /= X_train_std\n",
    "\n",
    "# X_val -= X_val_mean\n",
    "# X_val /= X_val_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nn_h1_build():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dims, init='glorot_normal', activation='sigmoid'))\n",
    "    model.add(Dense(output_dims, init='glorot_normal'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def nn_h2_build():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dims, init='glorot_normal', activation='sigmoid'))\n",
    "    model.add(Dense(128, input_dim=input_dims, init='glorot_normal', activation='tanh'))\n",
    "    model.add(Dense(128, input_dim=input_dims, init='glorot_normal', activation='relu'))\n",
    "    model.add(Dense(output_dims, init='glorot_normal'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def nn_h3_reg_build():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x - X_mean) / X_std, batch_input_shape=(None, input_dims)))\n",
    "    model.add(Dense(128, input_dim=input_dims, init='glorot_normal', activation='sigmoid'))\n",
    "    model.add(Dense(64, init='glorot_normal', activation='tanh', W_regularizer=l2(0.01), b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, init='glorot_normal', activation='tanh', W_regularizer=l2(0.01), b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(output_dims, init='glorot_normal',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def regularized_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dims, init='normal', activation='relu',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, input_dim=input_dims, init='normal', activation='relu',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(output_dims, init='normal',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def awesome_model():\n",
    "    model = Sequential([\n",
    "        Lambda(lambda x: (x - X_mean) / X_std, batch_input_shape=(None, input_dims)),\n",
    "        Dense(64, activation='tanh'),\n",
    "        Dense(64, activation='tanh'),\n",
    "        Dense(output_dims)\n",
    "    ])\n",
    "\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn_h3_reg_build()\n",
    "history = model.fit(X_train, y_train, verbose=False, nb_epoch=100, batch_size=10000, validation_data=(X_val, y_val))\n",
    "bokeh_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn_h2_build()\n",
    "history = model.fit(X_train, y_train, verbose=False, nb_epoch=100, batch_size=10000, validation_data=(X_val, y_val))\n",
    "bokeh_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model = awesome_model()\n",
    "history = model.fit(X_train, y_train, verbose=False, nb_epoch=100, batch_size=10000, validation_data=(X_val, y_val))\n",
    "bokeh_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn_h1_build()\n",
    "history = model.fit(X_train, y_train, verbose=False, nb_epoch=50, batch_size=10000, validation_data=(X_val, y_val))\n",
    "bokeh_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = regularized_model()\n",
    "history = model.fit(X_train, y_train, verbose=False, nb_epoch=100, batch_size=10000, validation_data=(X_val, y_val))\n",
    "bokeh_history(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Running Behavioral Cloned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_policy_fn(obs):\n",
    "    #Make prediction using standized data\n",
    "#     obs -= X_mean\n",
    "#     obs /= X_std\n",
    "    action = model.predict(obs)\n",
    "    #Cap the range to -.4 to +.4\n",
    "#     np.clip(action, -.4, .4, out=action)\n",
    "    return action[:,None].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "render = True\n",
    "max_timesteps = 1000\n",
    "num_rollouts = 10\n",
    "\n",
    "with tf.Session():\n",
    "    tf_util.initialize()\n",
    "\n",
    "    env = gym.make(envname)\n",
    "    max_steps = max_timesteps or env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    print(\"timestep_limit {}\".format(max_steps))\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    print(\"roll_outs --\")\n",
    "    obs = env.reset()\n",
    "    for i in tqdm(range(num_rollouts)):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = local_policy_fn(obs[None,:])\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "\n",
    "    print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return', np.std(returns))\n",
    "\n",
    "    expert_data = {'observations': np.array(observations),\n",
    "                   'actions': np.array(actions)}\n",
    "\n",
    "    # save and load\n",
    "    np.savez('traindata.npz', observations=np.array(observations), actions=np.array(actions))\n",
    "    data = np.load('traindata.npz') \n",
    "    print data.files \n",
    "    X = data['observations'] \n",
    "    y = data['actions']\n",
    "    print(\"observations-----------------{}\".format(X.shape))\n",
    "    print(\"actions----------------------{}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
